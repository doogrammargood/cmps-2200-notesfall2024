{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div#notebook {\n",
       " font-family: \"Exo_2\", sans-serif;\n",
       "}\n",
       "\n",
       ".rendered_html h1,\n",
       ".text_cell_render h1 {\n",
       " color: #126dce;\n",
       " font-size: 220%;\n",
       " text-align: center;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h2,\n",
       ".text_cell_render h2 {\n",
       " text-align: center;\n",
       " font-size: 170%;\n",
       " color: #126dce;\n",
       " font-style: normal;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h3,\n",
       ".text_cell_render h3 {\n",
       " font-size: 150%;\n",
       " color: #126dce;\n",
       " font-weight: lighter;\n",
       " text-decoration: italic;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h4,\n",
       ".text_cell_render h4 {\n",
       " font-size: 120%;\n",
       " color: #126dce;\n",
       " font-weight: underline;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h5,\n",
       ".text_cell_render h5 {\n",
       " font-size: 100%;\n",
       " color: #2f2f2f;\n",
       " font-weight: lighter;\n",
       " text-decoration: underline;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup\n",
    "from IPython.display import display,HTML\n",
    "display(HTML('<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>'))\n",
    "display(HTML(open('../rise.css').read()))\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import math\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5, rc={'figure.figsize':(12, 6)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CMPS-2200 Introduction to Algorithms: Genome Sequencing</h1>\n",
    "\n",
    "\n",
    "\n",
    "In this Jupyter Notebook, we will code Chapter 4 of the textbook Parallel Algorithms by Umut Acar. The point is to show the power of algorithms and give some examples before we dive into analysis and theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **genome** is a sequence of the letters from the alphabet {'A', 'C', 'G', 'T'}. \n",
    "\n",
    "We want to learn the human genome.\n",
    "\n",
    "The problem is that the human genome is very long (length ~3 billion), but we can only read snippets of length about 1000.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Breaking the problem into smaller pieces</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the problem, we use radiation to break the long genome sequence into smaller fragments randomly. Hopefully, each fragment will be small and can be sequenced. Then, we stitch the fragments together to recover the whole genome.\n",
    "\n",
    "We illustrate this method on a genome sequence of length $N=1000$. First, we create a random string that represents the genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=50 #length of the genome\n",
    "alphabet = ['a','c','g','t'] #alphabet for genome\n",
    "genome = ''.join(random.choices(alphabet,k=N)) #got this from here: https://www.geeksforgeeks.org/python-generate-random-string-of-given-length/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we simulate the effect of radiation that breaks the string into num_fragments many fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atgctgattagcggggccaagacaagttgcggcatttagggggatcttcc\n",
      "5\n",
      "5\n",
      "{'ggggatctt', 'cc', 'aagacaagttgcggcatttag', 'atgctgattagcggggc', 'c'}\n"
     ]
    }
   ],
   "source": [
    "num_fragments = N //10 #global variable that gives the number of fragments we divide the genome into.\n",
    "def create_fragments(genome,num_fragments):\n",
    "    frag_indices = random.sample(range(len(genome)), num_fragments-1) #Chooses num_fragments many indicies. See https://docs.python.org/3/library/random.html\n",
    "    frag_indices.sort()\n",
    "    frag_indices.append(None)\n",
    "    frag_indices=[0]+frag_indices #make sure to include the fragment that starts at 0.\n",
    "    parts = {genome [frag_indices[i]:frag_indices[i+1]] for i in range(len(frag_indices)-1)}#Splits the genome at the frag_indicies. See https://stackoverflow.com/questions/10851445/splitting-a-string-by-list-of-indices \n",
    "    return parts\n",
    "def check_num_fragments_works():\n",
    "    print(genome)\n",
    "    print(num_fragments)\n",
    "    frags = create_fragments(genome, num_fragments)\n",
    "    print(len(frags))\n",
    "    print(frags)\n",
    "check_num_fragments_works()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some strange things to notice:\n",
    "\n",
    "    1. The fragments are stored as a set, not a list. We lose information about the order of the fragments.\n",
    "    2. It is possible that some fragments could be duplicated, so there could be fewer than num_fragments many fragments.\n",
    "    3. It is possible that some fragments could be too long to sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot hope to recover the genome from one set of fragments, because the fragmentation process forfits all information about the order of these fragments. The solution to this is to fragment the same genome multiple times so that fragments from different calls to create_fragments can overlap. We can use the overlap to stitch the fragments together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate this, let us apply the create_fragments method 3 times. The total fragments that we will see are the union of the fragments from several applications. Call the number of applications num_times_fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ggccaagac', 'gacaagttgcg', 'atgctgat', 'aagtt', 'g', 'gcatttagggg', 'gggccaagacaagttgcggcatttagg', 'atgc', 'tagc', 'atgctgattagcgg', 'gatcttcc', 'tgattagcggggccaa', 'catttagggggatcttcc', 'gggatcttcc', 'gcgg'}\n"
     ]
    }
   ],
   "source": [
    "num_times_fragment = 3\n",
    "\n",
    "fragments = create_fragments(genome, num_fragments)\n",
    "for index in range(num_times_fragment -1):\n",
    "    fragments = fragments.union(create_fragments(genome, num_fragments))\n",
    "print(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, the fragments are small enough so that we can sequence them. Another benefit to dividing the genome into fragments is that all of the fragments can be sequenced in parallel (at the same time). Let as assume that we know these fragments. We must develop an algorithm to stitch these fragments back together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Stitching the fragments back together</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to stitch the fragments back into a genome. For example, we could just concatenate all of the fragments. Since there are mulitple ways, we rely on a <i>heuristic</i> to guide us to a reasonable solution. Our heuristic is to choose the shortest genome that is compatible with these fragments. This is justified by Occam's Razor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have another problem: How do we stitch the fragments together into the shortest possible genome that has the fragments as substrings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to simplify the problem, we can check the fragments to determine if one fragment is contained in another. If so, we discard the shorter fragment. We need a way to check if on substring is contained in another. We will give more details on this algorithm in the next lecture. For now, we use the python 'in' operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_subfragments(fragments):\n",
    "    fragments = {f for f in fragments if not any([f in other_frag and not f==other_frag for other_frag in fragments]) } #See https://realpython.com/python-string-contains-substring/ for this use of the 'in' operator to check substring membership.\n",
    "    return fragments\n",
    "\n",
    "def check_remove_subfragments_works():\n",
    "    test_frags = {\"a\",\"ata\", \"attta\", \"gcgc\", \"gcagc\", \"ta\", \"\"}\n",
    "    assert remove_subfragments(test_frags) == {'ata', 'attta', 'gcagc', 'gcgc'}\n",
    "check_remove_subfragments_works()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the function and remove any fragments that are substrings of another fragment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = remove_subfragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us convert fragments from a set into a list, so that each fragment can be identified by its index in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gggccaagacaagttgcggcatttagg', 'atgctgattagcgg', 'tgattagcggggccaa', 'catttagggggatcttcc', 'gcatttagggg']\n"
     ]
    }
   ],
   "source": [
    "fragments = list(fragments)\n",
    "print(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want the shortest possible genome compatible with these fragments, we may assume that each fragment only appears once in the genome. Thus, there is some order in which the fragments appear in the genome. If we knew this order, that we could stitch successive fragments together using the greatest possible overlap between successive pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, suppose that we only have two fragments: [\"agtgtg\",\"tgtgc\"] and that we know these fragments appear in this order. Then the genome containing these two fragments could be \"agtgtgc,\" \"agtgtgtgc\", \"agtgtgtgtgc\", or \"agtgtg*tgtgc\" where * means any string can occur. Clearly, the first string is the shortest, because it provides the greatest overlap between the two fragments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now write a function that calculates the overlap between two fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(string1, string2):\n",
    "    return max([index for index in range(min(len(string1), len(string2))) if string1[-index:]==string2[:index]], default =0 )\n",
    "\n",
    "def check_overlap_works():\n",
    "    str1 = \"abba\"\n",
    "    str2 = \"baab\"\n",
    "    str3 = \"abbabbabb\"\n",
    "    str4 = \"abbabbt\"\n",
    "    assert overlap(str1, str2) == 2\n",
    "    assert overlap(\"\", str2)==0\n",
    "    assert overlap(str2,\"\")==0\n",
    "    assert overlap(str3,str4) == 6\n",
    "\n",
    "check_overlap_works()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to work directly with the overlap when deciding how to stitch the strings together. However, the textbook recommends using a `distance' function that also takes the length of the strings into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_from_overlap(str1,str2):\n",
    "    return len(str2) - overlap(str1,str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance defined above is not quite a distance, since it is not symmetric. However, it has the nice property that, if we know the order of the fragments, the length of the shortest genome constructed from them is just the sum of the distances from one fragment to the next, assuming that we start at an empty fragment. Let's add in the empty fragment so that this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments=[\"\"] + fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the distances between all pairs of fragments using a doubly-nested list. Later, we will call this object an \"adjacency matrix.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'gggccaagacaagttgcggcatttagg', 'atgctgattagcgg', 'tgattagcggggccaa', 'catttagggggatcttcc', 'gcatttagggg']\n",
      "[[0, 27, 14, 16, 18, 11], [0, 25, 14, 16, 10, 2], [0, 25, 14, 6, 18, 10], [0, 20, 13, 16, 18, 11], [0, 27, 14, 16, 17, 11], [0, 24, 14, 16, 8, 10]]\n",
      "[0, 27, 14, 16, 18, 11]\n"
     ]
    }
   ],
   "source": [
    "all_pairs_of_distances = [[ distance_from_overlap(f1,f2) for f2 in fragments] for f1 in fragments]\n",
    "print(fragments)\n",
    "print(all_pairs_of_distances)\n",
    "print([len(a) for a in fragments])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I am noticing that there tend to be repeated rows in the adjacency matrix. idk why)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The Travelling Salesman</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the fragments as <i>nodes</i> and the distances between them as <i>edges</i> labeled by the distance. For example, for the fragments \"tagg\" \"catt\" \"gga\" \"gagtat\" \"tta\" and \"u\" (the emptystring) we can draw the following diagram.\n",
    "\n",
    "<img src=\"graph_from_fragments.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drawing suggests a map and transforms our problem (shortest superstring) into a different problem (traveling salesman). The new problem is to start at the emptystring, then follow the arrows to visit each fragment exactly once, then return to the emptystring so that the total sum of distances is minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The travelling salesman is an <i>NP-hard problem.</i> We will discuss this concept later, but for now this just means that the problem is considered difficult to solve. It is not that the problem is impossible to solve (uncomputable) but (to the best of our knoweledge) it would require too many resources (time, energy, dollars, etc) to solve the problem, even on moderately-sized instances.\n",
    "\n",
    "For example, the <i>brute force</i> solution is always availible: we consider all possible len(fragments)! ways to order the fragments and choose the ordering with the smallest sum of distances. However, it is not computationally feasible to check all possible permutations.\n",
    "\n",
    "There are better methods to find the optimal ordering of the fragments, but none of the known methods scale well as the number of fragments increases. There is a 1 million dollar bounty on this scaling problem, known as P=NP. In our case, we actually can solve the travelling salesman problem by using a library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 1, 5, 4] 50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from python_tsp.exact import solve_tsp_dynamic_programming #https://pypi.org/project/python_tsp/\n",
    "\n",
    "distance_matrix = np.array(all_pairs_of_distances)\n",
    "permutation, distance = solve_tsp_dynamic_programming(distance_matrix)\n",
    "print(permutation, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the cell above tells us how to re-order the fragments to produce the smallest genome that could have created them. Next we need to apply this order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordered fragments:  ['', 'atgctgattagcgg', 'tgattagcggggccaa', 'gggccaagacaagttgcggcatttagg', 'gcatttagggg', 'catttagggggatcttcc']\n",
      "overlaps between succesive pairs\n",
      "[0, 10, 7, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "ordered_fragments = [fragments[permutation[index]] for index in range(len(fragments))]\n",
    "#Let's show the re-ordered fragments and the overlaps between adjacent fragments\n",
    "if len(fragments)<25: #if we run this on a smaller set of fragments, let's inspect by eye that this re-ordering is good.\n",
    "    print(\"ordered fragments: \", ordered_fragments)\n",
    "    print(\"overlaps between succesive pairs\")\n",
    "    print([overlap(ordered_fragments[i], ordered_fragments[i+1])for i in range(len(ordered_fragments)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_fragments(frags): #assume that frags is a non-empty list of fragments, in the order that you want to stitch them.\n",
    "    trimmed_frags = [frags[0]]\n",
    "    for i in range(len(frags)-1):\n",
    "        trimmed_frags.append(frags[i+1][overlap(frags[i],frags[i+1]):] )\n",
    "    return ''.join(trimmed_frags)\n",
    "\n",
    "def test_stitch_fragments():\n",
    "    assert stitch_fragments(['', 'gtggcggttcatgcagactaattggccattcca', 'gactaattggccattccaaa', 'aatg', 'tgagtggtgggaagg']) ==\"gtggcggttcatgcagactaattggccattccaaatgagtggtgggaagg\"\n",
    "    #Overlaps between succesive fragments are [0, 18, 2, 2]\n",
    "test_stitch_fragments()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_genome = stitch_fragments(ordered_fragments)\n",
    "assert reconstructed_genome == genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assertion above usually passes, but not quite every time.\n",
    "\n",
    "We have succeeded in reconstructing the genome, but we need to answer some serious questions: Can we count on this to work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Scalability</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms are important for working on big problems. Small problems can be solved inefficiently, since they require little energy.\n",
    "\n",
    "The travelling salesman problem cannot be solved for massive parameters, like N=3 billion. However, it is too soon to give up. We turn to another heuristic that we will see in more detail later in the class. This is the concept of a <i>greedy algorithm</i>.\n",
    "\n",
    "A greedy algorithm reduces optimization problems (like traveling salesman) into a series of simple steps. At each step, the algorithm chooses the best option. The resulting solution is not always optimal, but sometimes it's good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_tour(distance_matrix): #Assume distance-matrix is a doubly nested array so that distance_matrix[i,j] is the distance from the ith fragment to the jth fragment.\n",
    "    current_index = 0\n",
    "    tour = [0]\n",
    "    unvisited_vertices = list(range(len(distance_matrix)))[1:] #we start at vertex 0\n",
    "    while len(unvisited_vertices)>0:\n",
    "\n",
    "        current_distance=math.inf        \n",
    "        for j in unvisited_vertices:\n",
    "            if distance_matrix[current_index][j]<current_distance:\n",
    "                next_index = j\n",
    "                current_distance= distance_matrix[current_index][j]\n",
    "        current_index = next_index\n",
    "        tour.append(current_index)\n",
    "        unvisited_vertices.remove(current_index)\n",
    "    return(tour) #Returns a sequence of indices, starting at index 0, that includes the index of each node exactly once.\n",
    "\n",
    "def test_greedy_tour():\n",
    "    A=[[0,2,5,3,1],[0,6,2,1,3],[0,9,9,8,11], [0,1,7,7,6,2], [0,4,3,1,2]]\n",
    "    assert greedy_tour(A) == [0, 4, 3, 1, 2]\n",
    "\n",
    "test_greedy_tour()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the greedy tour to order the fragments before stitching them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = greedy_tour(all_pairs_of_distances)\n",
    "ordered_fragments = [fragments[permutation[index]] for index in range(len(fragments))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we stitch these ordered fragments back together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "greedily_recovered_genome = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
