{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div#notebook {\n",
       " font-family: \"Exo_2\", sans-serif;\n",
       "}\n",
       "\n",
       ".rendered_html h1,\n",
       ".text_cell_render h1 {\n",
       " color: #126dce;\n",
       " font-size: 220%;\n",
       " text-align: center;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h2,\n",
       ".text_cell_render h2 {\n",
       " text-align: center;\n",
       " font-size: 170%;\n",
       " color: #126dce;\n",
       " font-style: normal;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h3,\n",
       ".text_cell_render h3 {\n",
       " font-size: 150%;\n",
       " color: #126dce;\n",
       " font-weight: lighter;\n",
       " text-decoration: italic;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h4,\n",
       ".text_cell_render h4 {\n",
       " font-size: 120%;\n",
       " color: #126dce;\n",
       " font-weight: underline;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h5,\n",
       ".text_cell_render h5 {\n",
       " font-size: 100%;\n",
       " color: #2f2f2f;\n",
       " font-weight: lighter;\n",
       " text-decoration: underline;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup\n",
    "from IPython.display import display,HTML\n",
    "display(HTML('<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>'))\n",
    "display(HTML(open('../rise.css').read()))\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5, rc={'figure.figsize':(12, 6)})\n",
    "# Bold formatting\n",
    "bold_start = \"\\033[1m\"\n",
    "bold_end = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Fast sorting</h1>\n",
    "\n",
    "Last time, we covered the basic sorting algorithms, Bubblesort, Selectionsort, and Insertionsort. These algorithms which run in $O(n^2)$ time in the worst case, where $n$ is the length of the list. This time, we will cover the faster sorting algorithms, mergesort and quicksort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Mergesort</h3>\n",
    "\n",
    "Mergesort applies the most obvious divide and conquer strategy to sorting. We divide the list into two roughly equal parts, then sort each part. We combine the two parts in a merge step.\n",
    "\n",
    "The merge step takes two sorted lists (let's call them list1 and list2) and returns a sorted list (new_list) that contains the items of both original lists. \n",
    "\n",
    "The basic operation of the merge step proceeds by finding the smallest item in list1 or list2. Since list1 is already sorted, we can extract its smallest item in $O(1)$ time by looking at its first item. Similarly, list2 is already sorted, so we can extract the smallest item of list2 in $O(1)$ time. The smaller of these two item is the smallest item of list1 or list2 and should be at the front of new_list.\n",
    "\n",
    "The merge step repeats this basic operation to repeatedly find the smallest item of list1 or list2 and puts that item next in new_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 | 1\n",
      "1,3\n",
      "---\n",
      "1 | 1,3\n",
      "1,1,3\n",
      "---\n",
      "8 | 1\n",
      "1,8\n",
      "---\n",
      "3 | 0\n",
      "0,3\n",
      "---\n",
      "1,8 | 0,3\n",
      "0,1,3,8\n",
      "---\n",
      "1,1,3 | 0,1,3,8\n",
      "0,1,1,1,3,3,8\n",
      "---\n",
      "2 | -4\n",
      "-4,2\n",
      "---\n",
      "92 | -4,2\n",
      "-4,2,92\n",
      "---\n",
      "2 | -10\n",
      "-10,2\n",
      "---\n",
      "45 | 6\n",
      "6,45\n",
      "---\n",
      "-10,2 | 6,45\n",
      "-10,2,6,45\n",
      "---\n",
      "-4,2,92 | -10,2,6,45\n",
      "-10,-4,2,2,6,45,92\n",
      "---\n",
      "0,1,1,1,3,3,8 | -10,-4,2,2,6,45,92\n",
      "-10,-4,0,1,1,1,2,2,3,3,6,8,45,92\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def merge_step(list1,list2):\n",
    "    #assumes list1 and list2 are sorted.\n",
    "    #Returns the list (list1+list2).sort()\n",
    "    new_list=[]\n",
    "    while(len(list1)>0 and len(list2)>0):\n",
    "        #Iteratively move the smaller of the smallest to the new list until one list is empty.\n",
    "        smallest_of_list1 = list1[0]\n",
    "        smallest_of_list2 = list2[0]\n",
    "        if smallest_of_list1<smallest_of_list2:\n",
    "            list1=list1[1:] #Removes the first item of list1\n",
    "            new_list.append(smallest_of_list1) #Puts that first item on new_list.\n",
    "        else:\n",
    "            list2 = list2[1:]\n",
    "            new_list.append(smallest_of_list2)\n",
    "    #At this point, at least one of list1 or list2 is empty. \n",
    "    #Put the remaining part of the nonempty list on the end of new_list.\n",
    "    if len(list1)==0:\n",
    "        new_list.extend(list2)\n",
    "    elif len(list2)==0:\n",
    "        new_list.extend(list1)\n",
    "    return new_list\n",
    "\n",
    "def mergesort(list_to_sort,quiet_mode = False):\n",
    "    #A divide-and-conquer method for sorting.\n",
    "    #list_to_sort is the input. quiet_mode is a boolean that determines whether partial outputs will be printed.\n",
    "    if len(list_to_sort)<=1: #Base case.\n",
    "        return list_to_sort\n",
    "    #The divide step:\n",
    "    middle = len(list_to_sort)//2 \n",
    "    list1 = list_to_sort[:middle] \n",
    "    list2 = list_to_sort[middle:] \n",
    "    #Conquer, recursively:\n",
    "    list1 = mergesort(list1,quiet_mode=quiet_mode)\n",
    "    list2 = mergesort(list2,quiet_mode=quiet_mode)\n",
    "    #Uncomment the next line to print the partial outputs.\n",
    "    if not quiet_mode:\n",
    "        print(','.join([str(l) for l in list1]), \"|\",','.join([str(l) for l in list2]))\n",
    "        print(','.join([ str(l) for l in merge_step(list1,list2)]))\n",
    "        print(\"---\")\n",
    "    #Complete conquering at this step by calling merge_step to combine the sorted lists, list1 and list2\n",
    "    return merge_step(list1,list2)\n",
    "\n",
    "def check_mergesort():\n",
    "    arbitrary_list = [1,3,1,8,1,3,0,92,2,-4,2,-10,45,6]\n",
    "    assert mergesort(arbitrary_list,quiet_mode=False)==sorted(arbitrary_list)\n",
    "check_mergesort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Analysis of mergesort</h3>\n",
    "\n",
    "Mergesort is a divide-and-conquer algorithm, so we can obtain a recursive equation for the worst-case runtime.\n",
    "\n",
    "This equation is $W_M(n)=2W_M(\\frac{n}{2})+\\Theta(n)$.\n",
    "\n",
    "Drawing the recursion tree and solving, we find that we are in the \"balanced\" case, and the runtime is $\\Theta(n\\log(n))$.\n",
    "\n",
    "The recursive equation makes it clear that we can parallelize mergesort easily by making both recursive calls in parallel.\n",
    "\n",
    "The span of mergesort is\n",
    "\n",
    "$S_M(n)=S_M(\\frac{n}{2})+\\Theta(n)$.\n",
    "\n",
    "Using this recursive equation, we see that the span is $n+\\frac{n}{2}+\\frac{n}{4}+\\dots \\leq 2n\\in O(n).$\n",
    "\n",
    "Actually, we can do better by parallelizing the merge step. There is no obvious way to paralellize the merege step, but we will show in the coming week that the merge step can be performed in $O(\\log(n))$ span by applying a clever trick. This means that the span of the improved mergesort algorithm $M^\\prime$ satisfies $S_{M^\\prime}(n) = S_{M^\\prime}(\\frac{n}{2})+O(\\log(n))$. By repeatedly applying this recursive equation, we obtain \n",
    "\\begin{align*}\n",
    "S_{M^\\prime}(n)=\\sum_{i=0}^{\\log(n)}O(\\log(2^i))=\\sum_{i=0}^{\\log(n)}O(i) =O((\\log(n))^2)\\end{align*}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Quicksort</h3>\n",
    "\n",
    "Quicksort is another divide-and-conquer approach to sorting. The idea is simple: Designate some item of the list as the \"pivot.\" Then, compare each other item to the pivot and move the item before or after the pivot according to that comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quicksort(arr,quietmode=False): #Code generated by ChatGPT3.5\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    pivot_index = len(arr) // 2\n",
    "    pivot = arr[pivot_index] #Chooses the pivot to be in the middle.\n",
    "    left = [x for x in arr if x < pivot]\n",
    "    middle = [x for x in arr if x == pivot]\n",
    "    right = [x for x in arr if x > pivot]\n",
    "    if not quietmode:\n",
    "        #We print the unsorted array with the pivot in bold.\n",
    "        print(','.join([str(l) for l in arr[:pivot_index]]) + f\",{bold_start}\" + str(pivot) +f\"{bold_end},\" + ','.join([str(l) for l in arr[pivot_index+1:]]))\n",
    "        #Then we print what it will look like when you move relative to the pivot.\n",
    "        print(','.join([str(l) for l in left]) +f\",{bold_start}\"+','.join([str(l) for l in middle])+f\"{bold_end},\" + ','.join([str(l) for l in right]))\n",
    "        print('---')\n",
    "    return quicksort(left,quietmode=quietmode) + middle + quicksort(right,quietmode=quietmode) #Makes two recursive calls.\n",
    "\n",
    "def check_quicksort():#Test was not generated by ChatGPT\n",
    "    arbitrary_list = [1,3,1,8,1,3,0,92,2,-4,2,-10,45,6]\n",
    "    assert quicksort(arbitrary_list,quietmode=True)==sorted(arbitrary_list)\n",
    "check_quicksort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Analysis of quicksort</h3>\n",
    "\n",
    "Quicksort is a divide-and-conquer-method. The recursive formula depends on the input. The combine step takes $O(n)$ work, because we must compare each of $n-1$ items to the pivot. After each comparison, we can move the items to the appropriate place in constant time.\n",
    "\n",
    "<h5>Details on the combine step</h5>\n",
    "Let's analyze moving the items to their appropriate places in contsant time. We saw in the case of insertion sort that this movement can sometimes be resource-intensive, so we should be careful here. The Python implementation runs in linear time, but it uses list-slicing so it requires additional memory and is therefore not an in-place sorting method.\n",
    "\n",
    "Here's one way to perform the combine step of quicksort in-place.\n",
    "\n",
    "- Loop through the list and count the size of left, middle, and right.\n",
    "- Swap the items of middle into their places. Note the index of the last item in middle.\n",
    "- Initialize left and right counters to 0. These counters count the number of items that have been correctly placed in left and right, respectively.\n",
    "- Loop through the list again. Only progress to the next item if the item currently considered does not move.\n",
    "- Every time you encounter an item that should go to left, swap it with the item at the index of the left counter. Increment the left counter.\n",
    "- Every time you encounter an item that should go to right, swap it with the item at the index of the right counter plus the index of the last item in middle. Increment the right counter.\n",
    "- Every time you encounter an item that should go to middle, keep it where it is.\n",
    "\n",
    "We looped through the list twice. The first loop just compares and counts, so it takes $O(n)$ time. At each step in the second loop, the left counter increases, or the right counter increases, or an item of middle is encountered. Thus, the total amount of work in the second loop is $O(n)$. This shows that $O(n)$ is the amount of work for the combine step.\n",
    "\n",
    "<h5>Worst case analysis of Quicksort</h5>\n",
    "\n",
    "In the worst case, each pivot is the largest (or smallest) item of the list. This leads to an unbalanced recursion, where all of the work is on the recursive call to the left (or right) part of the list. In this case, the recursive equation for quicksort is\n",
    "\n",
    "\\begin{align*}\n",
    "W_{Quicksort}(n)=W_{Quicksort}(n-1)+W_{Quicksort}(1) + \\Theta(n).\n",
    "\\end{align*}\n",
    "\n",
    "Unraveling the recursive equation, we find that\n",
    "\\begin{align*}\n",
    "W_{Quicksort}(n)=\\sum_{i=0}^n \\Theta(i) \\in \\Theta(n^2).\n",
    "\\end{align*}\n",
    "\n",
    "It's clear that the worst-case span of quicksort obeys the same recursive equation and is also $\\Theta(n^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Average case analysis of Quicksort:</h3>\n",
    "\n",
    "Sorting problems have an easily-defined average-case behavior. The average is the average over all $n!$ permutations of the list, where we assume that each permutation is equally likely. This relies on the fact that our sorting algorithms only use comparisons, and are blind to the actual items in the list. Thus, effectively, there are only finitely many inputs and we can define an average distribution as the uniform distribution over these finitely many inputs.\n",
    "\n",
    "<h5>Heuristic argument for average case of Quicksort</h5>\n",
    "\n",
    "The worst-case behavior of quicksort occurs when every single pivot is the maximal or minimal item. This would be extremely unlucky. In general, we should expect that the pivot will be somewhere in the middle of the list. Let's assume that the pivot is at index $cn$, where $0\\leq c\\leq n$ each time.\n",
    "\n",
    "\\begin{align*}A_{Quicksort}(n) \\approx A_{Quicksort}(cn) +A_{Quicksort}((1-c)n) + O(n)\\end{align*}.\n",
    "\n",
    "Each level of the recursion tree has the same cost, $O(n)$. The number of levels is somewhere between $\\log_{\\frac{1}{c}}(n)$ and $\\log_{\\frac{1}{1-c}}(n)$. Up to asymptotics, the base of the logarithm does not matter, as long as $c\\neq 0,1$. There are $\\Theta(\\log(n))$ levels. Therefore, the total work in the average case is abount $\\Theta(n\\log(n))$.\n",
    "\n",
    "<h5>Careful analysis of Quicksort average case</h5>\n",
    "\n",
    "The Heuristic argument assumed that the pivot is always at index $cn$. Technically, we must be much more careful and keep track of the probabilities that the index is at $cn$. There is a better argument to analyze the average case behavior of quicksort. Our analsis is simplified if we assume that the values of the items are unique. In this case, each item can be identified with a number in $\\{0,1,\\dots,n-1\\}$ that is its index after the list is sorted.\n",
    "\n",
    "Let $X_{i,j}$ be a random variable (depending on the permutation of the $n$ items) that is $0$ if item $i$ is not compared to item $j$ and $1$ otherwise. Since $X_{i,j}$ is an indicator random variable(its values are $0$ and $1$), its expected value is the probability that $i$ is compared with $j$. Let $X= \\sum_{i<j}X_{i,j}$ be the random variable that records the number of comparisons being made. Linearity of expectation states that $\\mathbb{E}(X) = \\sum_{i<j}\\mathbb{E}(X_{i,j})$. In other words, to calculate the average number of comparisons, we calculate the probability that pairs will be compared and sum these probabilities.\n",
    "\n",
    "At each step of quicksort, we only compare items to the pivot. To calculate $\\mathbb{E}(X_{i,j})$ (the probability a pair of items $x leq y$ will be compared) note that choosing the permutation randomly amounts to choosing the pivots uniformly at random. Since we are assuming that the values of the items are unique, the probability that $i$ is compared with $j$ is precisely the probability that $i$ or $j$ is chosen to be the pivot before any of the items in the set $\\{k \\in list \\mid i<k<j \\}$. This gives us $\\mathbb{E}(X_{i,j})=\\frac{2}{j-i+1}$.\n",
    "\n",
    "Thus, the total work of quicksort in the average case is \n",
    "\n",
    "\\begin{align*}\n",
    "    A_{Quicksort}(n)= \\sum_{0\\leq i<j< n} \\mathbb{E}(X_{i,j}) = \\sum_{0\\leq i<j< n} \\frac{2}{j-i+1}.\n",
    "\\end{align*}\n",
    "\n",
    "Let's change variables and set $x=i-j+1$. Each value of $x$ can be realized as $n-x+1$ different values of $i$ and $j$.\n",
    "\n",
    "\\begin{align*}\n",
    "   A_{Quicksort}(n) = \\sum_{2\\leq x \\leq n} (n-x+1) \\frac{2}{x} = ((n+1)\\sum_{2\\leq x \\leq n} \\frac{2}{x})-2(n-1)\n",
    "\\end{align*}\n",
    "\n",
    "Next, we use the nice trick of summing the harmonic series via integral: \n",
    "\\begin{align*}\n",
    "\\sum_{2\\leq x \\leq n} \\frac{2}{x} \\leq 2\\int_{x=1}^n \\frac{1}{x} = \\log(n).\n",
    "\\end{align*}\n",
    "\n",
    "The inequality in the middle comes from interpreting the summation as a Riemann sum. Since the terms in the sum are decreasing, we can approximate the sum with an integral. The $\\frac{1}{x}$ curve passes through the top-right corner of each rectangle in Riemann sum, and is therefore an upper bound. The trick completes the argument that\n",
    "\n",
    "\\begin{align*}\n",
    "A_{Quicksort}(n) \\in O(n\\log(n)).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Parallelizing Quicksort</h3>\n",
    "\n",
    "The story of parallelizing quicksort is similar to that of mergesort. Both are divide-and-conquer algorithms, so both can be parallelized by simply making the recursive calls in parallel. This pararellization procedure produces an algorithm with $O(n)$ span. Again, there is a clever way to parallelize the combination step so that its span is $\\Theta(\\log(n))$. This makes the span of quicksort $(\\log(n))^2$, on average.\n",
    "\n",
    "The combine step of quicksort involves comparing every item to the pivot, then moving that item to the appropriate place relative to the pivot. It is easy to compare all items to the pivot in parallel with constant span. We can just assign a different process to compare each item to the pivot. The hard part is moving the items in parallel. Naively, following our detailed description of the combine procedure from these notes, it would seem that we need to place the find the first item in left before we can place the second item in left.\n",
    "\n",
    "The clever trick to parallelize the combine step of quicksort is the same trick that parallelizes the combine step of mergesort. The trick allows us to calculate left count in parallel, using $\\Theta(\\log(n))$ span. Then each item that moves to left also knows exactly where it's supposed to go and can move in a single step. The same story holds for the items that go to the right and middle.\n",
    "\n",
    "This week, we will show how you can count in parallel using the scan function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Entropic bound on comparison-based sorting</h3>\n",
    "\n",
    "The sorting methods that we have seen all have worst-case work $\\Omega(n\\log(n))$. Here is a well-known argument that every sorting method based on comparisons must have worst-case work $\\Omega(n\\log(n))$.\n",
    "\n",
    "Let us assume that the input is a permutation. The sorting algorithm will perform various comparisons and re-order the items according to the inverse permutation. This means that we need to perform enough comparisons to collect enough information so that our algorithm can have a different behavior for each permutation.\n",
    "\n",
    "There are $n!$ permutations. If we perform $k$ comparisons, there are only $2^k$ possibilities for the outcomes of these comparisons. We are using the fact that the input is a permutation, so comparisons only have $2$ outcomes. Therefore,\n",
    "\n",
    "\\begin{align*}\n",
    "2^k \\geq n! \\iff \\log(k) &\\geq \\log(n!)\\\\\n",
    "k &\\geq \\log(\\prod_{i=1}^n i)\\\\\n",
    "k &\\geq \\sum_{i=1}^n \\log(i) \\geq \\sum_{i=\\frac{n}{2}}^n \\log(i) \\\\\n",
    "k &\\geq \\sum_{i=\\frac{n}{2}}^n \\log(\\frac{n}{2})\\\\\n",
    "k &\\geq \\frac{n}{2}\\log(\\frac{n}{2})\\in \\Omega(n\\log(n)).\n",
    "\\end{align*}\n",
    "\n",
    "This shows that, asymptotically, we need at least $n\\log(n)$ comparisons in order to correctly sort a list of $n$ items. This is called the <i>entropic bound</i> because it compares the amount of information needed to handle any of the $n!$ permutations with the amount of information that is collected via comparisons.\n",
    "\n",
    "<h3>Exceptions to the entropic bound</h3>\n",
    "\n",
    "The entropic bound applies to sorting methods that are based on comparsions. We can circumvent the bound by relaxing this assumption, or possibly by introducing new assumptions on the list of things to sort.\n",
    "\n",
    "As a first example, let's add the additional assumption that we seek to sort the numbers $0,\\dots,n-1$, and that these numbers are assumed to be at indicies $0,\\dots,n-1$. Under these additional assumptions, we can sort in linear time. First, examine the number at index $0$. If that number is $i$, swap it with the number at index $i$. Now, the number at index $i$ is in its correct place. Repeat until the correct number is at index $0$, then move onto the next index.\n",
    "\n",
    "Each step in the algorithm involves only a single swap, but increases the number of correctly placed items by $1$. So this is a linear time algorithm. Note that it does not involve comparisons. The catch is that we assume that we are sorting the numbers $0,\\dots,n-1$. I think this algorithm is a modification of [cycle sort](https://watermark.silverchair.com/330365.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA4swggOHBgkqhkiG9w0BBwagggN4MIIDdAIBADCCA20GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMWwnceXYbIKGEk-SoAgEQgIIDPs3w4usLz3XPCnWo-sSXCCGcve7CCvPQqpq9xt9x5X-Aesjx0Ek4Hllj7YlCH1ZsMkFBgKft7bhbZ3tNvKky7N2EAjpkYUGmWxYprbHdQwMmco8N3BuI0SnEkvn5dHzi5PKPar79_yT-qK8CDdj4-3HvIKQZn8h1cZpIuz2y0E9PCxxVO0PcCr2YAM6ew7v26ek_46wFZbCP8eu_3RsPvmmcO5WPK0hlBqiNl9pWr-mpTWdY5AtYtlEpQGnsr9Sjs6nVuIQNZ5kB2Qdhwj4HzhtuO4Px9HiHPdSqa2vdDwkPyYHKAbSwNkiwrZfNzH_oxx8gUe-ju6yzAIFMWvEGlMf4SYHu_17f3ZAfKpAq13qhRf4mGxTExrnRNADhRF_0B2fGB3vemr4DplVspRKZ7jsThyvuiSF1_ueqCObHFtnFTz87lrNtC9qMNGMw897hWfQLJTxhFV2oBRPy9a5hCfE0NZqtoZ7WMJH6wIcFsGMFSwSWVo2fDB0k7iuQF4FABd6kzD-9JqvKfBy9FBvcWVO-VfFj58ehl5thfrd15e0_gmyAxm9ayNvk8bSavNSwuemBL6nESgaFD1ARWyIy-3M8ngPJOUSD2R9WvWlLpKbQuNQpYMzls6L5BXIdZnJEVcH8glB_Dzi8NR6k219DFe4Mvg5Iwm69VKIc4HrdrT6X8KY0MKNIEIZdpHpLYRlY70qf_ic_enlvpM-cm9r17j0wmqzxwjEuN7dGaudQfAX6KHlzU2-e3RVIXVu9Djr7irYDENKG0_90T_OnSeS6juhn6LEGLQP4xTTOr1nQiUNLRnryWKDLq3ksE39lklRxFECuoq7p3A1C9qDJVH-SCOp_kUxvv8CSuYP6ZExir109j5pWPzYBmu2OONAxYa5DZ-YIziRYh_kSD0aStQfgLXvx8h7wiPjoojvqFnnat6iQPs_otAX9BbR84De7dvEzEs09xZGrlOWE-KY0A99i-ifuOdAix2ELijog3FYQmbQ-VNg8_Q65WTijZgfWbr6WpIJTQ0zXGOQO_spGxXGndd53-Wlc2oF48Rpv-tLyO7fm3GZXbdaLZmhY0rfGfTy7rwA6cdEOSpTsRozPzU66).\n",
    "\n",
    "<h3>Counting Sort: linear time sorting</h3>\n",
    "\n",
    "Counting is an alternative operation to comparing that we can use to implement our sorting algorithms. [source](https://www.geeksforgeeks.org/counting-sort/). Counting sort is a sorting algorithm that is particularly useful when there are many items but few values. Let $n$ denote the number of items and $k$ denote the maximum value. We assume that the values are natural numbers.\n",
    "\n",
    "The idea behind counting sort is to loop through the list and count the number of items with each value. We maintain a separate list, whose length is at least $k$. Call this the count list, and the original list the item list. The $i^{th}$ index of the count list represents the number of items in the item list with value $k$. Initially, the count list has $0$ at each entry. Each time we encounter an item with value $i$ as we loop through the item list, we increment the value of the $i^{th}$ index of the count list. This takes $O(n)$ work.\n",
    "\n",
    "Next, we loop through the count list and replace its $i^{th}$ value with the sum of the first $i$ values of the count list. This takes $O(k)$ time. After this operation, for any value $v$ that appears in the list, count list at index $v$ contains the largest integer such $i$ such that the $i^{th}$ item output list has value $v$.\n",
    "\n",
    "Finally, we loop through the item list again. When we see the $i^{th}$ item with value $v$, we look up the value at index $v$ in the count list. The value at index $v$ in the count list indicates where to put the $i^{th}$ item of the count list in the output list. We decrement the value of count list at index $v$ after adding the $i^{th}$ item to the output list. This involves only $O(1)$ work per item in the item list and so is $O(n)$ work total.\n",
    "\n",
    "The total work of the algorithm is $O(n+k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item list:  [1, 3, 1, 8, 1, 3, 0, 92, 2, 4, 2, 10, 45, 6]\n",
      "count list before summing:  [1, 3, 2, 2, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count list after summing:  [1, 4, 6, 8, 9, 9, 10, 10, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14]\n",
      "output_list: [0, 1, 1, 1, 2, 2, 3, 3, 4, 6, 8, 10, 45, 92]\n"
     ]
    }
   ],
   "source": [
    "def count_sort(item_list, quiet_mode = True): #from https://www.geeksforgeeks.org/counting-sort/\n",
    "    # Finding the maximum item of input_list.\n",
    "    M = max(item_list)\n",
    "\n",
    "    # Initializing count_list with 0\n",
    "    count_list = [0] * (M + 1)\n",
    "    \n",
    "    # Mapping each item of item_list as an index of count_list\n",
    "    for num in item_list:\n",
    "        count_list[num] += 1\n",
    "\n",
    "    copy_of_count_list_before_summing = count_list[:]\n",
    "    # Calculating prefix sum at every index of count_list\n",
    "    for i in range(1, M + 1):\n",
    "        count_list[i] += count_list[i - 1]\n",
    "    copy_of_count_list_after_summing = count_list[:]\n",
    "    # Creating output_array from count_list\n",
    "    output_list = [0] * len(item_list)\n",
    "\n",
    "    for i in range(len(item_list) - 1, -1, -1):\n",
    "        output_list[count_list[item_list[i]] - 1] = item_list[i]\n",
    "        count_list[item_list[i]] -= 1\n",
    "    if quiet_mode==False:\n",
    "        print(\"item list: \",item_list)\n",
    "        print(\"count list before summing: \", copy_of_count_list_before_summing)\n",
    "        print(\"count list after summing: \", copy_of_count_list_after_summing)\n",
    "        print(\"output_list:\", output_list)\n",
    "\n",
    "    return output_list\n",
    "\n",
    "def check_counting_sort():\n",
    "    arbitrary_list = [1,3,1,8,1,3,0,92,2,4,2,10,45,6] #Apparently, this implementation does not work for negative values.\n",
    "    assert count_sort(arbitrary_list,quiet_mode = False)==sorted(arbitrary_list)\n",
    "check_counting_sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see that counting can be parallelized to operate in $\\Theta(\\log(n))$ span. I believe this makes the span of counting sort $\\Theta(\\log(n)+\\log(k))$. Consider this a conjecture for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
