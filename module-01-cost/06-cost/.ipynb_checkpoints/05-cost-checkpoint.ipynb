{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rise.css'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display,HTML\n\u001b[1;32m      3\u001b[0m display(HTML(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<style>.prompt\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mwidth: 0px; min-width: 0px; visibility: collapse}</style>\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m display(HTML(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrise.css\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# imports\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rise.css'"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "from IPython.display import display,HTML\n",
    "display(HTML('<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>'))\n",
    "display(HTML(open('rise.css').read()))\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5, rc={'figure.figsize':(12, 6)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CMPS 2200\n",
    "# Introduction to Algorithms\n",
    "\n",
    "## Cost models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today's agenda:\n",
    "\n",
    "- Three different ways to model computational cost\n",
    "  + Random Access Machine\n",
    "  + Parallel Random Access Machine\n",
    "  + Language Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall first lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def linear_search(mylist, key):        #   cost         number of times run\n",
    "    for i,v in enumerate(mylist):      #   c1               n\n",
    "        if v == key:                   #   c2               n\n",
    "            return i                   #   c3               0\n",
    "    return -1                          #   c4               1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\hbox{Cost(linear-search, } n) = c_1n + c_2n + c_4 = O(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## machine-based cost model\n",
    "\n",
    "- define the cost of each instruction  \n",
    "- runtime is sum of costs of each instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Access Machine model\n",
    "\n",
    "- \"Simple\" operations (+, *, =, if) take exactly one time step\n",
    "  - no matter the size of operands\n",
    "- loops consist of many single-step operations\n",
    "- **memory access takes one step**\n",
    "  - unbounded memory\n",
    "  - each cell holds integers of unbounded size\n",
    "- assumes sequential execution\n",
    "- one input tape, one output tape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hypothetically, we could compute the run time of an algorithm:\n",
    "1. compute the number of steps\n",
    "2. determine the number of steps per second our machine can perform\n",
    "3. time = steps / steps per second\n",
    "\n",
    "\n",
    "All models make incorrect assumptions. What are some that the RAM model makes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- multiplication does not take the same time as addition\n",
    "- cache is faster than RAM\n",
    "\n",
    "<br>\n",
    "\n",
    "Not terrible assumptions since we are interested in asymptotic analysis.\n",
    "\n",
    "E.g., if cache lookup is half the time of RAM lookup, then we're \"only\" off by a factor of 2.  \n",
    "E.g. $2n \\in O(n)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PRAM: Parallel Random Access Machine\n",
    "\n",
    "- The RAM model extended to have \n",
    "  - multiple processors $P_0, P_1, P_2 \\ldots$\n",
    "  - unbounded, **shared** memory cells $M[0], M[1], M[2] \\ldots$\n",
    "  - any processor $P_i$ can access any memory cell $M[j]$ in one time step\n",
    "  \n",
    "![pram.jpg](../figures/pram.jpg)  \n",
    "[source](https://www.tutorialspoint.com/parallel_algorithm/parallel_random_access_machines.htm)\n",
    "\n",
    "<br>\n",
    "Assumes some control mechanisms to deal with race conditions/synchronization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To compute the runtime:\n",
    "- compute time for the slowest processor\n",
    "\n",
    "\n",
    "<br><br>\n",
    "Two drawbacks of this model:\n",
    "\n",
    "1. Mapping data to each processor can be tricky\n",
    "2. Nested parallelism is hard to specify in this model (e.g., recursive fork-join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Language Based Cost  Models\n",
    "\n",
    "- Define a language to specify algorithms\n",
    "- Assign a cost to each expression\n",
    "- Cost of algorithm is sum of costs for each expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Work-Span model\n",
    "\n",
    "- We can define this model for SPARC\n",
    "\n",
    "Recall our definitions of **work** and **span**\n",
    "\n",
    "- **work**: total number of primitive operations performed by an algorithm\n",
    "\n",
    "- **span**: longest sequence of dependencies in computation\n",
    "    - time to run with an infinite number of processors\n",
    "    - measure of how \"parallelized\" an algorithm is \n",
    "    - also called: *critical path length* or *computational depth*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**intuition**:  \n",
    "**work**: total energy consumed by a computation  \n",
    "**span**: minimum possible time that the computation requires\n",
    "\n",
    "<br>\n",
    "        \n",
    "**work**: $T_1$ = time using one processor  \n",
    "**span**: $T_\\infty$ = time using $\\infty$ processors\n",
    "\n",
    "For a given SPARC expression $e$, we will analyze the work $W(e)$ and span $S(e)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Composition\n",
    "\n",
    "<img src=\"../figures/composition.png\" width=\"50%\"/>\n",
    "\n",
    "\n",
    "-   $(e_1, e_2)$: Sequential Composition\n",
    "\n",
    "    -   Add work and span\n",
    "\n",
    "-   $(e_1 || e_2)$: Parallel Composition\n",
    "\n",
    "    -   Add work but **take the maximum span**\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Rules of composition\n",
    "\n",
    "\n",
    "|        $\\mathbf{e}$   |        $\\mathbf{W(e)}$         |        $\\mathbf{S(e)}$         |\n",
    "| --------------------- | ------------------------------ | ------------------------------ |\n",
    "|       $v$             |              $1$               |             $1$                |\n",
    "|$\\mathtt{lambda}\\:p\\:.\\:e$|              $1$            |             $1$                |\n",
    "|     $(e_1, e_2)$      |     $1 + W(e_1) + W(e_2)$      |     $1 + S(e_1) + S(e_2)$      |\n",
    "|    $(e_1 \\| e_2)$     |     $1 + W(e_1) + W(e_2)$      |   $1 + \\max(S(e_1), S(e_2))$   |\n",
    "| $(e_1 e_2)$           |  $W(e_1) + W(e_2) + W([\\hbox{Eval}(e_2)/x]e_1) + 1$ | $S(e_1) + S(e_2) + S([\\hbox{Eval}(e_2)/x]e_1) + 1$ |\n",
    "|   `let val` $x=e_1$ `in` $e_2$ `end`  |  $1 + W(e_1) + W([\\hbox{Eval}(e_1)/x]e_2)$       |     $1 + S(e_1) +     S([\\hbox{Eval}(e_1)/x]e_2)$  |\n",
    "| $\\{f(x)\\mid x\\in A\\}$ |   $1+\\sum_{x\\in A} W(f(x))$    |   $1+\\max_{x\\in A} S(f(x))$    |\n",
    "\n",
    "\n",
    "## parallel composition: $e_1 || e_2$\n",
    "\n",
    "$W(e_1 || e_2) = 1 + W(e_1) + W(e_2)$  \n",
    "$S(e_1 || e_2) = 1 + \\max(S(e_1), S(e_2))$  \n",
    "\n",
    "What are we assuming here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In a *pure* functional language, we can run two functions in parallel if there is no explicit sequencing.\n",
    "\n",
    "- no side effects\n",
    "- data persistence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## function application: $e_1 e_2$\n",
    "\n",
    "$W(e_1 e_2) = W(e_1) + W(e_2) + W([\\hbox{Eval}(e_2)/x]e_1) + 1$  \n",
    "\n",
    "\n",
    "\n",
    "- $\\hbox{Eval}(e)$ evaluates $e$ and returns resulting value\n",
    "- $[v/x]e$: replace all free (unbound) occurrences of $x$ in $e$ with value $v$ \n",
    "  - e.g., $[10/x](x^2+10) \\rightarrow 110$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "$e_1 e_2$\n",
    "\n",
    "\n",
    "E.g., if $e_1$ is $f(x)$, we  \n",
    "1. evaluate $e_2$ to a value $v$\n",
    "2. substitute $v$ for $x$ in $f(x)$\n",
    "3. run $f(v)$\n",
    "\n",
    "\n",
    "We assume $\\hbox{Eval}(e_2) = \\hbox{lambda} \\: x \\: . \\: e_2$\n",
    "\n",
    "$[\\hbox{Eval}(e_2)/x]e_1$: all free occurrences of $x$ in $e_1$ are replaced with $\\hbox{Eval}(e_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Defs: \n",
    "\n",
    "$W(e_1 e_2) = W(e_1) + W(e_2) + W([\\hbox{Eval}(e_2)/x]e_1) + 1$  \n",
    "\n",
    "$\\hbox{Eval}(e_2) = \\hbox{lambda} \\: x \\: . \\: e_2$\n",
    "\n",
    "$W(\\mathtt{lambda}\\:p\\:.\\:e) = 1$\n",
    "\n",
    "<br>\n",
    "\n",
    "Example\n",
    "\n",
    "$f(x) = \\mathtt{lambda} \\: x \\: . \\: x + 1$\n",
    "\n",
    "<br>\n",
    "\n",
    "$W(f(x)(1)) =$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$W(\\mathtt{lambda} \\: x \\: . \\: x + 1) + W(1) + W([\\hbox{Eval}(1) / x](x + 1)) + 1 =$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$W(\\mathtt{lambda} \\: x \\: . \\: x + 1) + W(1) + ( W(\\hbox{lambda} \\: x \\: . \\: 1) + W(x+1) + 1 ) + 1 =$\n",
    "\n",
    "$1 + 1 + 1 + 1 + 1 + 1 =$  \n",
    "\n",
    "$6$\n",
    "\n",
    "<br>\n",
    "$S(f(x)(1)) = 6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**serial composition:**\n",
    "\n",
    "$W(f(x)(1), f(x)(2)) = $\n",
    "\n",
    "$W(f(x)(1)) + W(f(x)(2)) + 1 = $\n",
    "\n",
    "$6 + 6 + 1 = 12$  \n",
    "\n",
    "<br>\n",
    "\n",
    "$S(f(x)(1), f(x)(2)) = $\n",
    "\n",
    "$S(f(x)(1)) + S(f(x)(2)) + 1 = $\n",
    "\n",
    "$6 + 6 + 1 = 12$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**parallel composition:**\n",
    "\n",
    "$W(f(x)(1) || f(x)(2)) = $\n",
    "\n",
    "$W(f(x)(1)) + W(f(x)(2)) + 1 =$\n",
    "\n",
    "$6 + 6 + 1 = 11$  \n",
    "\n",
    "<br>\n",
    "\n",
    "$S(f(x)(1) ||  f(x)(2)) = $\n",
    "\n",
    "$\\max(S(f(x)(1)), S(f(x)(2))) + 1 =$\n",
    "\n",
    "$\\max(6,6) + 1 = 7$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = lambda x: x**2 + 10\n",
    "e2 = lambda y: 5*y\n",
    "\n",
    "e1(\n",
    "    e2(2)  # evaluate e2 to a value v\n",
    "  )        # substitute v for x in e1\n",
    "           # return result of e1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## let ... in\n",
    "\n",
    "$W($ `let val`$x=e_1$ `in` $e_2$ `end`$) = 1 + W(e_1) + W([\\hbox{Eval}(e_1)/x]e_2)$\n",
    "\n",
    "Expression $e_2$ is applied using the bindings defined inside **let**.\n",
    "\n",
    "\n",
    "\n",
    "- $[\\hbox{Eval}(e_1)/x]e_2$: all free occurrences of $x$ in $e_2$ are replaced with $\\hbox{Eval}(e_1)$\n",
    "- $W([\\hbox{Eval}(e_1)/x]e_2)$ accounts for this cost.\n",
    "\n",
    "\n",
    "$\\texttt{let}$  \n",
    "$~~~~x = 10*5 ~~~~~ (e_1$)  \n",
    "$\\texttt{in}$   \n",
    "$~~~~x + 100  ~~~~~~~~~~ (e_2)$  \n",
    "$\\texttt{end}$ \n",
    "<br>\n",
    "\n",
    "returns 150\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "$W($ `let val`$x=e_1$ `in` $e_2$ `end`$) = $   \n",
    "\n",
    "$1 + W(e_1) +  W([\\hbox{Eval}(e_1)/x]e_2) = $  \n",
    "\n",
    "$1 + W(e_1) + (W(\\hbox{sub in 50 for x}) + W(x+100) + 1)$ (by function application rule)  \n",
    "\n",
    "$1 + 1 + 1 + 1 + 1 $  \n",
    "\n",
    "$=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelism\n",
    "\n",
    "how many processors can we use efficiently?\n",
    "\n",
    "\n",
    "**average parallelism**: \n",
    "\n",
    "$$\n",
    "\\overline{P} = \\frac{W}{S}\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "To increase parallelism, we can either:\n",
    "- decrease span\n",
    "- increase work (but that's not really desireable, since we want the overall cost to be low)\n",
    "\n",
    "<br>\n",
    "\n",
    "**work efficiency**: a parallel algorithm is *work efficient* if it performs asymptotically the same work as the best known sequential algorithm for the problem.\n",
    "\n",
    "So, we want a *work efficient* parallel algorithm with low span.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scheduling\n",
    "\n",
    "Key issue of parallel algorithms is **scheduling**: which processor will run which task when?\n",
    "- typically have more tasks than processors.\n",
    "\n",
    "Recall our parallel sum method:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<img src=\"../figures/dag-sum.png\" alt=\"dag-sum\" width=\"450\"/>\n",
    "\n",
    "[source](https://homes.cs.washington.edu/~djg/teachingMaterials/spac/sophomoricParallelismAndConcurrency.pdf)\n",
    "\n",
    "We must decide when to run each part of the sum. There are dependencies that constrain the order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scheduler\n",
    "- For each task generated by a parallel algorithm, assign it to an available processor\n",
    "- Goal: minimize execution time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Greedy Scheduler\n",
    "\n",
    "Whenever there is a processor available and a task ready to execute, assign the task to the processor and start it immediately. \n",
    "\n",
    "Why might this not be optimal?\n",
    "\n",
    "<img src=\"../figures/greedy.png\" alt=\"greedy\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Greedy schedulers have an important property that is summarized by the greedy scheduling principle.\n",
    "\n",
    "Assuming $P$ processors, then the time $T_P$ to perform computation with work $W$ and span $S$ is bounded by:\n",
    "\n",
    "$T_P < \\frac{W}{P} + S$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Because we know:  \n",
    "- $T_P \\ge \\frac{W}{P}$, since that would be the optimal division of work to processors\n",
    "- $T_P \\ge S$, by the definition of span\n",
    "\n",
    "we can conclude that the best we can hope for is:\n",
    "\n",
    "$T_P \\ge \\mathrm{max}(\\frac{W}{P},S)$\n",
    "\n",
    "Therefore the time using a greedy scheduler is bounded by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "$ \\mathrm{max}(\\frac{W}{P},S) \\le T_P < \\frac{W}{P} + S$\n",
    "\n",
    "<br>\n",
    "How good is greedy? How close is $(\\frac{W}{P} + S)$ to $\\mathrm{max}(\\frac{W}{P},S)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "actually pretty close.\n",
    "\n",
    "$\\frac{W}{P} + S \\le 2 * \\mathrm{max}(\\frac{W}{P},S)$\n",
    "\n",
    "(why? consider what the worst possible span is...)\n",
    "\n",
    "<br>\n",
    "\n",
    "Greedy scheduler gets better the more parallelism is possible in the algorithm.\n",
    "\n",
    "Recall average parallelism: $\\overline{P} = \\frac{W}{S}$\n",
    "\n",
    "We can rewrite:\n",
    "\n",
    "$T_P < \\frac{W}{P} + S$  \n",
    "$~~~~= \\frac{W}{P} + \\frac{W}{\\overline{P}}$  \n",
    "$~~~~=\\frac{W}{P}(1+\\frac{P}{\\overline{P}})$\n",
    "\n",
    "\n",
    "So, the greater $\\overline{P}$ is than $P$, the closer to optimal we get.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "E.g., recall our parallel sum method, which has\n",
    "\n",
    "$W=O(n)$  \n",
    "$S=O(\\lg n)$\n",
    "\n",
    "<br>\n",
    "$\\overline{P} = \\frac{W}{S} = \\frac{O(n)}{O(\\lg n)}$\n",
    "\n",
    "<br>\n",
    "\n",
    "$ \\mathrm{max}(\\frac{W}{P},S) \\le T_P < \\frac{W}{P} + S$\n",
    "\n",
    "<br>\n",
    "so, if we have 2 processors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "$\\mathrm{max}(\\frac{O(n)}{2},O(\\lg n)) \\le T_2 < \\frac{O(n)}{2} + O(\\lg n)$\n",
    "\n",
    "$\\frac{O(n)}{2} \\le T_2 < \\frac{O(n)}{2} + O(\\lg n)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "if we have $\\lg n$ processors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "$\\mathrm{max}(\\frac{O(n)}{\\lg n},O(\\lg n)) \\le T_{\\lg n} < \\frac{O(n)}{\\lg n} + O(\\lg n)$\n",
    "\n",
    "$\\frac{O(n)}{\\lg n} \\le T_{\\lg n} < \\frac{O(n)}{\\lg n} + O(\\lg n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "The advantage of the Work-Span model:\n",
    "\n",
    "- We can design parallel algorithms without worrying about scheduling details.\n",
    "\n",
    "- We are ignoring some overhead in the creation of the schedule itself.\n",
    "  - This is acceptable since we are focused on asymptotics (just as in RAM model)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rise": {
   "autolaunch": true,
   "controls": false,
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "fade"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
