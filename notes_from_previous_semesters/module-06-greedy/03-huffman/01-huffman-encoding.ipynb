{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div#notebook {\n",
       " font-family: \"Exo_2\", sans-serif;\n",
       "}\n",
       "\n",
       ".rendered_html h1,\n",
       ".text_cell_render h1 {\n",
       " color: #126dce;\n",
       " font-size: 220%;\n",
       " text-align: center;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h2,\n",
       ".text_cell_render h2 {\n",
       " text-align: center;\n",
       " font-size: 170%;\n",
       " color: #126dce;\n",
       " font-style: normal;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h3,\n",
       ".text_cell_render h3 {\n",
       " font-size: 150%;\n",
       " color: #126dce;\n",
       " font-weight: lighter;\n",
       " text-decoration: italic;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h4,\n",
       ".text_cell_render h4 {\n",
       " font-size: 120%;\n",
       " color: #126dce;\n",
       " font-weight: underline;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h5,\n",
       ".text_cell_render h5 {\n",
       " font-size: 100%;\n",
       " color: #2f2f2f;\n",
       " font-weight: lighter;\n",
       " text-decoration: underline;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML('<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>'))\n",
    "display(HTML(open('../rise.css').read()))\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5, rc={'figure.figsize':(12, 6)})\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<style>.jp-RenderedHTMLCommon table {\n",
    "  border-collapse: collapse;\n",
    "  border-spacing: 0;\n",
    "  border: none;\n",
    "  color: var(--jp-ui-font-color1);\n",
    "  font-size: 20px;\n",
    "  table-layout: fixed;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}</style>\n",
    "\n",
    "# CMPS 2200\n",
    "# Introduction to Algorithms\n",
    "\n",
    "## Data Compression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Agenda:\n",
    "\n",
    "- Huffman Coding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Document encoding\n",
    "\n",
    "If we are given a document $D$ in which we use the alphabet $\\Sigma = \\{\\sigma_1 \\ldots \\sigma_k\\}$, our goal is to create a binary encoding of $\\Sigma$ to represent $D$ with as few bits as possible. \n",
    "\n",
    "Of course, the encoding must distinctly represent $\\Sigma$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Example: \n",
    "\n",
    "Suppose $\\Sigma=\\{A, B, C, D\\}$, and document $D = \\langle A, A, A, A, A, A, A, A, A, B, C, D\\rangle$. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive encoding could be:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "|$$\\sigma$$|$$e(\\sigma)$$         |\n",
    "|-------|-----------------------|\n",
    "| A     | 00 |\n",
    "| B     | 01 |\n",
    "| C     | 10 | \n",
    "| D     | 11 |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "This is a **fixed-length** encoding of $\\Sigma$. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What is the number of bits required to encode the entire document with this encoding?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The length of the document with this encoding is $2\\cdot 12 = 24$. The encoding is:\n",
    "\n",
    "$e(D) = \\texttt{\"}000000000000000000011011\\texttt{\"}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A more space-efficent encoding?\n",
    "\n",
    "Fixed-length encoding doesn't account for redundancy in the document. \n",
    "\n",
    "Intuitively, we should encode the document by the frequency of the characters in the alphabet. The more frequent the character, the smaller its code should be.\n",
    "\n",
    "$D = \\langle A, A, A, A, A, A, A, A, A, B, C, D\\rangle$\n",
    "\n",
    "|$$\\sigma$$ | $$f(\\sigma)$$|\n",
    "|-------|---------------|\n",
    "| A     | 9 |\n",
    "| B     | 1 |\n",
    "| C     | 1 | \n",
    "| D     | 1 |\n",
    "\n",
    "> Let $f: \\sigma \\rightarrow \\mathbb{Z}$ be the number of times a character appears in $D$; this is easily computed in $O(|D|)$ work. (What about the span?)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "So, following that logic, we could come up with a code like this:\n",
    "\n",
    "|$$\\sigma$$ |$$e'(\\sigma)$$|\n",
    "|-------|---------------|\n",
    "| A     | 0   |\n",
    "| B     | 1  |\n",
    "| C     | 00 | \n",
    "| D     | 11 |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Is this a valid encoding?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "How should we decode `11`?\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Unambiguous Encoding\n",
    "\n",
    "Instead, we could use:\n",
    "\n",
    "|$$\\sigma$$ |$$e'(\\sigma)$$|\n",
    "|-------|---------------|\n",
    "| A     | 0   |\n",
    "| B     | 10  |\n",
    "| C     | 110 | \n",
    "| D     | 111 |\n",
    "\n",
    "This **variable-length** encoding is unambiguous.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "For our document $D = \\langle A, A, A, A, A, A, A, A, A, B, C, D\\rangle$, we get the encoding:\n",
    "\n",
    "$e'(D) = \"00000000010110111\"$\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "This has length $1\\cdot 9 + 2\\cdot 1 + 3\\cdot 1 + 3\\cdot 1 = 17$. So this is a bit better (we got a length of 24 before). \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimizing the cost of encoding\n",
    "\n",
    "Given a document $D$ in which we use the alphabet $\\Sigma = \\{\\sigma_1 \\ldots \\sigma_k\\}$, our goal is to create a binary encoding of $\\Sigma$ to represent $D$ with as few bits as possible. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "In general, the cost of a given encoding $e$ is \n",
    "\n",
    "$$C(e) = \\sum_{i=0}^{|D|} |e(D[i])| = \\sum_{\\sigma\\in\\Sigma} f(\\sigma)\\cdot e(\\sigma).$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Over all possible valid encodings $e: \\Sigma \\rightarrow \\{0,1\\}^*$, we want to find a variable-length encoding $e_*$ so that $C(e_*)$ is minimized.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encodings as Trees\n",
    "\n",
    "How do we ensure that a variable-length encoding is valid? In other words, how do we only consider variable-length encodings that are *prefix-free*?\n",
    "\n",
    "We can think of an encoding as representing a tree, with characters from $\\Sigma$ as leaves. Note that a fixed-length encoding has all leaves at the same level. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "For the two encodings we gave, we'd have:\n",
    "\n",
    "<img src = \"figures/encoding_trees.jpg\" width=\"60%\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prefix-free encodings\n",
    "Every prefix-free encoding $e$ can be represented by a tree $T_e$. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "The depth of each character $d_T(\\sigma)$ in the tree determines how many bits are needed to encode $\\sigma$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "So the optimal compression of $D$ can be achieved by identifying the encoding tree $T$ that minimizes:\n",
    "\n",
    "$$C(T) = \\sum_{\\sigma\\in\\Sigma} f(\\sigma)\\cdot d_T(\\sigma)$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We want to build a prefix-free encoding that is optimal. \n",
    "\n",
    "Claude Shannon and Robert Fano came up with [methods](https://en.wikipedia.org/wiki/Shannon%E2%80%93Fano_coding) for building prefix-free encodings, but they aren't optimal.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "David Huffman (as a graduate student in Fano's class) came up with a *bottom-up* greedy algorithm to build prefix-free encodings as a class project and was able to prove that it was optimal.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Huffman Coding\n",
    "\n",
    "\n",
    "Intuitively we know we should ensure that when constructing an encoding tree, the higher the frequency, the shorter the path length.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Conversely, the lowest frequency characters should be on the lowest levels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "The main idea of Huffman's algorithm is to choose the two **least** frequent characters $x$ and $y$ from $\\Sigma$ and create a subtree with $x$ and $y$ as sibling leaves for the final encoding. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "We then remove $x$ and $y$ from $\\Sigma$ and add a *new* character $z$ with frequency $f(x)+f(y)$, and recurse to compute a tree $T'$. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "The final tree $T$ is just $T'$ with $z$ replaced by the subtree with $x, y$ as siblings. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<img src=\"figures/huffman_example.jpg\" width=\"60%\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Proof of Optimality\n",
    "\n",
    "**Greedy Choice**: Let $x, y\\in\\Sigma$ have the two smallest frequencies ($f(x) \\leq f(y)$). Then there is an optimal encoding $T$ for $\\Sigma$ with $x, y$ as sibling leaves at maximum depth. \n",
    "\n",
    "**Proof**: First let us observe that in an optimal solution $T^*$, $x$ must have maximum depth. Suppose that it did not, and some character $a$ with frequency $f(a)$ had depth $d_{T^*}(a) > d_{T^*}(x)$. Then we can construct a new tree $T^{**}$ by swapping them. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<img src = \"figures/huffman_exchange_argument.jpg\" width = \"30%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "The cost will be:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "$\\begin{align}\n",
    "C(T^{**}) &=& C(T^*) - f(a)d_{T^*}(a)  - f(x)d_{T^*}(x) + f(x)d_{T^*}(a) + f(a)d_{T^*}(x) \\\\\n",
    "&=& C(T^*) - (f(a)d_{T^*}(a) + f(x)d_{T^*}(x) - f(x)d_{T^*}(a) - f(a)d_{T^*}(x)) \\\\\n",
    "&=& C(T^*) - (f(a)-f(x))(d_{T^*}(a) - d_{T^*}(x)) \\\\\n",
    "\\end{align}$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "If $f(a) > f(x)$ then $C(T^{**}) < C(T^*)$. This is a contradiction. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "So this means that we can swap $a$ and $x$ without changing the cost and thus some optimal solution has $x$ as a maximum depth leaf. $\\blacksquare$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Why are $x$ and $y$ siblings? Now we can apply the same swapping argument as above to establish that $y$ is a sibling of $x$ in some optimal solution.\n",
    "\n",
    "\n",
    "**Optimal Substructure**: Let $\\Sigma' = \\Sigma - \\{x, y\\} \\cup \\{z\\}$, where $z\\not\\in \\Sigma$ is a character with frequency $f(z) = f(x) + f(y)$. \n",
    "\n",
    "If $T'$ is an optimal encoding for $\\Sigma'$, then an optimal encoding $T$ for $\\Sigma$ can be constructed from $T'$ by replacing the leaf representing $z$ with an internal node that has $x, y$ as children. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "**Proof**: We first make a useful observation of the relationship between the cost of $T$ and $T'$. Observe that:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "$\\begin{align}\n",
    "C(T) &=& \\sum_{\\sigma\\in\\Sigma} f(\\sigma)d_T(\\sigma) \\\\\n",
    "&=& f(x)d_T(x) + f(y)d_T(y) + \\sum_{\\sigma\\in\\Sigma - \\{x,y\\}} f(\\sigma)d_T(\\sigma) \\\\\n",
    "&=& f(x)(1+d_T(z)) + f(y)(1+d_T(z)) + \\sum_{\\sigma\\in\\Sigma - \\{x,y\\}} f(\\sigma)d_T(\\sigma) \\\\\n",
    "&=& (f(x)+f(y))(1+d_T(z)) + \\sum_{\\sigma\\in\\Sigma - \\{x,y\\}} f(\\sigma)d_T(\\sigma) \\\\\n",
    "&=& (f(z))(1+d_T(z)) + \\sum_{\\sigma\\in\\Sigma - \\{x,y\\}} f(\\sigma)d_T(\\sigma) \\\\\n",
    "&=& f(z)+f(z)d_T(z) + \\sum_{\\sigma\\in\\Sigma - \\{x,y\\}} f(\\sigma)d_T(\\sigma) \\\\\n",
    "&=& f(z) + C(T') \\\\\n",
    "\\end{align}$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> **Optimal Substructure**: Let $\\Sigma' = \\Sigma - \\{x, y\\} \\cup \\{z\\}$, where $z\\not\\in \\Sigma$ is a character with frequency $f(z) = f(x) + f(y)$. If $T'$ is an optimal encoding for $\\Sigma'$, then an optimal encoding $T$ for $\\Sigma$ can be constructed from $T'$ by replacing the leaf representing $z$ with an internal node that has $x, y$ as children. \n",
    "\n",
    "We've established\n",
    "\n",
    "$C(T) = f(z) + C(T')$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Suppose that $T$ was not optimal, and that there was some other tree $Z$ with $C(Z) < C(T).$\n",
    "\n",
    "We can assume that $Z$ must have the two smallest frequency characters as siblings at maximum depth as established above. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Now let's construct $Z'$ by removing $x, y$ and adding $z$ with $f(z) = f(x)+f(y)$. \n",
    "\n",
    "$Z'$ is an encoding for $\\Sigma'$, and we have that $C(Z) = f(z) + C(Z')$. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "By our assumption $C(Z) < C(T)$, so $f(z) + C(Z') < f(z) + C(T')$ using the observation above. \n",
    "\n",
    "But this is a contradiction to the optimality of $T'$ since we now have that $C(Z') < C(T').$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Thus Huffman coding produces an optimal prefix-free encoding. $\\blacksquare$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Implementation and Runtime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Heaps allow us to efficiently retrieve and insert nodes.\n",
    "\n",
    "<img src=\"figures/huffman-heap-2.png\" width=\"70%\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "**Huffman's Algorithm:**\n",
    "\n",
    "Initialize a min-heap with character frequencies $f(\\sigma)$\n",
    "\n",
    "Then, repeat:\n",
    "\n",
    "2. Call `deleteMin` twice to get the two least frequent nodes $x$ and $y$\n",
    "3. Create a new node $z$ with frequency $f(x) + f(y)$\n",
    "4. Make $x$ and $y$ children of $z$ in the tree.\n",
    "4. Call `insert` to add $z$ to the heap\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Work and Span\n",
    "\n",
    "> **Huffman's Algorithm**\n",
    ">\n",
    "> Initialize a min-heap with character frequencies $f(\\sigma)$\n",
    ">\n",
    "> Then, repeat:\n",
    "> 1. Call `deleteMin` twice to get the two least frequent nodes $x$ and $y$\n",
    "> 2. Create a new node $z$ with frequency $f(x) + f(y)$\n",
    "> 3. Make $x$ and $y$ children of $z$ in the tree.\n",
    "> 4. Call `insert` to add $z$ to the heap\n",
    "\n",
    "Work/span?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Because every iteration reduces the number of nodes by 1, there will be $n$ iterations (where $n = |\\Sigma|$).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- The cost of 2 calls to `deleteMin` and one call to `insert` is $3 \\lg n$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Thus, total work is $O(n \\lg n)$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Span?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "No parallelism, so the span is also $O(n \\lg n)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decoding\n",
    "\n",
    "So how do we use Huffman coding in practice?\n",
    "\n",
    "Given a document $D$, we would compute frequencies and then construct an encoding tree $T$. Then to store the compressed version of $D$ we save the encoding of $\\Sigma$, the tree $T$ and the encoded version of $D$. To decode a document, we would read bits sequentially and traverse $T$, emitting the appropriate character from $\\Sigma$ whenever we hit a leaf. \n",
    "\n",
    "What is the worst-case work of decoding a document?\n",
    "\n",
    "<img src = \"figures/encoding_trees.jpg\" width=\"60%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$00000000010110111 \\rightarrow \\langle A, A, A, A, A, A, A, A, A, B, C, D\\rangle$\n",
    "\n",
    "- We start at the root, and descend the tree until we reach a leaf.\n",
    "- Then, we return to the root and repeat\n",
    "\n",
    "So, if the input has $n$ bits, we will visit each bit exactly once.\n",
    "\n",
    "$\\Rightarrow O(n)$\n",
    "\n",
    "which is equivalent to the total cost of the encoding tree:\n",
    "\n",
    "$\\Rightarrow O(C(T))$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "David Huffman invented his coding algorithm as a student in [1951](https://en.wikipedia.org/wiki/Huffman_coding#History), so it has been around for about 70 years. Yet it is still ubiquitous! \n",
    "\n",
    "Huffman coding is optimal in the sense that no other prefix code can achieve a shorter average code length. In practice we must identify the best alphabet to use for the coding, i.e., finding the best way to decompose a file into binary \"blocks\" to get good compression.\n",
    "\n",
    "Both [ZIP](https://en.wikipedia.org/wiki/Zip_file_format) and [MP3](http://www.mp3-tech.org/programmer/docs/mp3_theory.pdf) file formats use Huffman coding as a last step after numerous preprocessing steps.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "rise": {
   "autolaunch": true,
   "controls": false,
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "fade"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
